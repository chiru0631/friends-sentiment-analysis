{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":88330,"databundleVersionId":10113261,"sourceType":"competition"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport numpy as np\nimport pandas as pd\n\n\n# paths to the dataset with encoding B specified\ntrain_df = pd.read_csv('/kaggle/input/ml-hackathon-ec-campus-set-3-alt/train/text.csv', encoding='ISO-8859-1')\ntest_df = pd.read_csv('/kaggle/input/ml-hackathon-ec-campus-set-3-alt/test/text.csv', encoding='ISO-8859-1')\n\n# Print the first five rows dataset\nprint(train_df.head())\nprint(test_df.head())\n\n# Check the shape of the datasets\nprint(\"Train_shape:\", train_df.shape)\nprint(\"Test_shape:\", test_df.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T18:44:44.760076Z","iopub.execute_input":"2024-11-11T18:44:44.760768Z","iopub.status.idle":"2024-11-11T18:44:44.797304Z","shell.execute_reply.started":"2024-11-11T18:44:44.760701Z","shell.execute_reply":"2024-11-11T18:44:44.796112Z"}},"outputs":[{"name":"stdout","text":"   Sr No.                                      Utterance          Speaker  \\\n0       4  So lets talk a little bit about your duties.  The Interviewer   \n1      18       No, I-I-I-I don't, I actually don't know           Rachel   \n2      40       He was with her when he wrote this poem.           Phoebe   \n3      53                                            Hi.           Rachel   \n4      69                            Which part exactly?             Joey   \n\n  Sentiment  Dialogue_ID  Utterance_ID  Season  Episode     StartTime  \\\n0   neutral            0             3       8       21  00:16:26,820   \n1  negative            1             3       9       23  00:36:49,290   \n2   neutral            3             3       3       12  00:10:21,078   \n3   neutral            4             6       3       11   0:20:30,873   \n4   neutral            6             3       8       22   0:12:31,655   \n\n        EndTime  \n0  00:16:29,572  \n1  00:36:51,791  \n2  00:10:23,496  \n3   0:20:31,135  \n4   0:12:33,657  \n   Sr No.                                          Utterance Speaker  \\\n0      62              So why dont you give me your number?    Joey   \n1      72                               Whats fish hooking?  Monica   \n2     112                          Ross, we can handle this.  Monica   \n3     120  Now wh-what is more important, love or silliness?    Ross   \n4     136  Y'know, this kind of co-dependant, emotionally...   Roger   \n\n   Dialogue_ID  Utterance_ID  Season  Episode     StartTime       EndTime  \n0            5             8       4       20  00:15:00,024  00:15:02,275  \n1            7             6       3       24  00:03:44,474  00:03:46,924  \n2           12             1       6        3  00:12:41,510  00:12:44,637  \n3           12             9       6        3  00:13:27,389  00:13:32,310  \n4           13             5       1       13  00:20:06,872  00:20:20,384  \nTrain_shape: (1000, 10)\nTest_shape: (100, 9)\n","output_type":"stream"}],"execution_count":77},{"cell_type":"code","source":"#Load and Link Data with Video Paths\"\nimport os\nimport pandas as pd\n\n# Load training and testing datasets with specified encoding to handle special characters\ntrain_df = pd.read_csv('/kaggle/input/ml-hackathon-ec-campus-set-3-alt/train/text.csv', encoding='ISO-8859-1')\ntest_df = pd.read_csv('/kaggle/input/ml-hackathon-ec-campus-set-3-alt/test/text.csv', encoding='ISO-8859-1')\n\n#  Define directory locations for training and testing video files\ntrain_video_friends = '/kaggle/input/ml-hackathon-ec-campus-set-3-alt/train/videos'\ntest_video_friends = '/kaggle/input/ml-hackathon-ec-campus-set-3-alt/test/videos'\n\n#  Function to construct the path for each video clip based on dialogue and utterance IDs\ndef construct_video_path(row, video_path):\n    dialogue_id = row['Dialogue_ID']\n    utterance_id = row['Utterance_ID']\n    filename = f\"dia{dialogue_id}_utt{utterance_id}.mp4\"\n    return os.path.join(video_path, filename)\n\n# Apply the function to each row to create a new column for video file paths\ntrain_df['video_clip_path'] = train_df.apply(construct_video_path, axis=1, video_path=train_video_friends)\ntest_df['video_clip_path'] = test_df.apply(construct_video_path, axis=1, video_path=test_video_friends)\n\n# Display sample rows to verify the video paths are added accurately\nprint(train_df[['Dialogue_ID', 'Utterance_ID', 'video_clip_path']].head())\nprint(test_df[['Dialogue_ID', 'Utterance_ID', 'video_clip_path']].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T18:44:44.799600Z","iopub.execute_input":"2024-11-11T18:44:44.800054Z","iopub.status.idle":"2024-11-11T18:44:44.856717Z","shell.execute_reply.started":"2024-11-11T18:44:44.800002Z","shell.execute_reply":"2024-11-11T18:44:44.855643Z"}},"outputs":[{"name":"stdout","text":"   Dialogue_ID  Utterance_ID  \\\n0            0             3   \n1            1             3   \n2            3             3   \n3            4             6   \n4            6             3   \n\n                                     video_clip_path  \n0  /kaggle/input/ml-hackathon-ec-campus-set-3-alt...  \n1  /kaggle/input/ml-hackathon-ec-campus-set-3-alt...  \n2  /kaggle/input/ml-hackathon-ec-campus-set-3-alt...  \n3  /kaggle/input/ml-hackathon-ec-campus-set-3-alt...  \n4  /kaggle/input/ml-hackathon-ec-campus-set-3-alt...  \n   Dialogue_ID  Utterance_ID  \\\n0            5             8   \n1            7             6   \n2           12             1   \n3           12             9   \n4           13             5   \n\n                                     video_clip_path  \n0  /kaggle/input/ml-hackathon-ec-campus-set-3-alt...  \n1  /kaggle/input/ml-hackathon-ec-campus-set-3-alt...  \n2  /kaggle/input/ml-hackathon-ec-campus-set-3-alt...  \n3  /kaggle/input/ml-hackathon-ec-campus-set-3-alt...  \n4  /kaggle/input/ml-hackathon-ec-campus-set-3-alt...  \n","output_type":"stream"}],"execution_count":78},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# Initialize TF-IDF Vectorizer for text feature extraction (limited to 500 features)\ntfidf = TfidfVectorizer(max_features=500)\n\n# Apply TF-IDF transformation on 'Utterance' column to obtain text-based features\ntrain_friends_text_features = tfidf.fit_transform(train_df['Utterance']).toarray()\ntest_friends_text_features = tfidf.transform(test_df['Utterance']).toarray()\n\n# Merge the generated text features with the original DataFrames for future use\ntrain_df = pd.concat([train_df, pd.DataFrame(train_friends_text_features)], axis=1)\ntest_df = pd.concat([test_df, pd.DataFrame(test_friends_text_features)], axis=1)\n\n# Display the first few rows to confirm the features were correctly appended\nprint(train_df.head())\nprint(test_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T18:44:44.858145Z","iopub.execute_input":"2024-11-11T18:44:44.858631Z","iopub.status.idle":"2024-11-11T18:44:44.918334Z","shell.execute_reply.started":"2024-11-11T18:44:44.858578Z","shell.execute_reply":"2024-11-11T18:44:44.917189Z"}},"outputs":[{"name":"stdout","text":"   Sr No.                                      Utterance          Speaker  \\\n0       4  So lets talk a little bit about your duties.  The Interviewer   \n1      18       No, I-I-I-I don't, I actually don't know           Rachel   \n2      40       He was with her when he wrote this poem.           Phoebe   \n3      53                                            Hi.           Rachel   \n4      69                            Which part exactly?             Joey   \n\n  Sentiment  Dialogue_ID  Utterance_ID  Season  Episode     StartTime  \\\n0   neutral            0             3       8       21  00:16:26,820   \n1  negative            1             3       9       23  00:36:49,290   \n2   neutral            3             3       3       12  00:10:21,078   \n3   neutral            4             6       3       11   0:20:30,873   \n4   neutral            6             3       8       22   0:12:31,655   \n\n        EndTime  ...  490  491  492  493  494  495  496  497       498  499  \n0  00:16:29,572  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.356949  0.0  \n1  00:36:51,791  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  \n2  00:10:23,496  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  \n3   0:20:31,135  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  \n4   0:12:33,657  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  \n\n[5 rows x 511 columns]\n   Sr No.                                          Utterance Speaker  \\\n0      62              So why dont you give me your number?    Joey   \n1      72                               Whats fish hooking?  Monica   \n2     112                          Ross, we can handle this.  Monica   \n3     120  Now wh-what is more important, love or silliness?    Ross   \n4     136  Y'know, this kind of co-dependant, emotionally...   Roger   \n\n   Dialogue_ID  Utterance_ID  Season  Episode     StartTime       EndTime  \\\n0            5             8       4       20  00:15:00,024  00:15:02,275   \n1            7             6       3       24  00:03:44,474  00:03:46,924   \n2           12             1       6        3  00:12:41,510  00:12:44,637   \n3           12             9       6        3  00:13:27,389  00:13:32,310   \n4           13             5       1       13  00:20:06,872  00:20:20,384   \n\n                                     video_clip_path  ...  490  491  492  493  \\\n0  /kaggle/input/ml-hackathon-ec-campus-set-3-alt...  ...  0.0  0.0  0.0  0.0   \n1  /kaggle/input/ml-hackathon-ec-campus-set-3-alt...  ...  0.0  0.0  0.0  0.0   \n2  /kaggle/input/ml-hackathon-ec-campus-set-3-alt...  ...  0.0  0.0  0.0  0.0   \n3  /kaggle/input/ml-hackathon-ec-campus-set-3-alt...  ...  0.0  0.0  0.0  0.0   \n4  /kaggle/input/ml-hackathon-ec-campus-set-3-alt...  ...  0.0  0.0  0.0  0.0   \n\n   494  495  496       497       498  499  \n0  0.0  0.0  0.0  0.204941  0.392181  0.0  \n1  0.0  0.0  0.0  0.000000  0.000000  0.0  \n2  0.0  0.0  0.0  0.000000  0.000000  0.0  \n3  0.0  0.0  0.0  0.000000  0.000000  0.0  \n4  0.0  0.0  0.0  0.081135  0.310524  0.0  \n\n[5 rows x 510 columns]\n","output_type":"stream"}],"execution_count":79},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport pandas as pd\nimport cupy as cp  # GPU acceleration library\nfrom tqdm import tqdm  # To monitor progress\n\n# Function to extract features from video frames, using GPU for faster computation\ndef extract_video_features_on_gpu(video_path):\n    frame_features = []\n    cap = cv2.VideoCapture(video_path)\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        # Resize frame to 224x224 using GPU\n        frame_gpu = cp.array(cv2.resize(frame, (224, 224)))  # Convert to GPU array using cupy\n        # Flatten the frame to a 1D vector and append to feature list\n        frame_features.append(cp.asnumpy(frame_gpu).flatten())  # Transfer back to CPU for further processing\n\n    cap.release()\n    \n    # Return the mean of the features (alternative to using deep learning features)\n    return np.mean(frame_features, axis=0) if frame_features else np.zeros((224 * 224 * 3,))\n\n# Initialize list to store video features for the training set\ntrain_video_features_list = []\n\n# Using tqdm to display a progress bar while processing video files\nfor video_path in tqdm(train_df['video_clip_path']):\n    train_video_features_list.append(extract_video_features_on_gpu(video_path))\n\n# Convert the extracted features to a DataFrame for easy integration\ntrain_video_features_df = pd.DataFrame(train_video_features_list)\n\n# Merge the video features with the original DataFrame (reset index for alignment)\ntrain_df = pd.concat([train_df.reset_index(drop=True), train_video_features_df], axis=1)\n\n# Display the DataFrame with the newly added features\nprint(train_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T18:44:44.921357Z","iopub.execute_input":"2024-11-11T18:44:44.921914Z","iopub.status.idle":"2024-11-11T18:49:36.512477Z","shell.execute_reply.started":"2024-11-11T18:44:44.921859Z","shell.execute_reply":"2024-11-11T18:49:36.511449Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 1000/1000 [03:37<00:00,  4.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"   Sr No.                                      Utterance          Speaker  \\\n0       4  So lets talk a little bit about your duties.  The Interviewer   \n1      18       No, I-I-I-I don't, I actually don't know           Rachel   \n2      40       He was with her when he wrote this poem.           Phoebe   \n3      53                                            Hi.           Rachel   \n4      69                            Which part exactly?             Joey   \n\n  Sentiment  Dialogue_ID  Utterance_ID  Season  Episode     StartTime  \\\n0   neutral            0             3       8       21  00:16:26,820   \n1  negative            1             3       9       23  00:36:49,290   \n2   neutral            3             3       3       12  00:10:21,078   \n3   neutral            4             6       3       11   0:20:30,873   \n4   neutral            6             3       8       22   0:12:31,655   \n\n        EndTime  ...      150518     150519     150520      150521  \\\n0  00:16:29,572  ...   37.803030  23.969697  36.242424   36.757576   \n1  00:36:51,791  ...  106.050000  98.816667  87.583333  101.316667   \n2  00:10:23,496  ...  105.413793  90.965517  94.017241  105.500000   \n3   0:20:31,135  ...    7.000000   3.000000   5.200000    6.800000   \n4   0:12:33,657  ...    2.645833   6.666667   0.458333    3.041667   \n\n       150522     150523      150524      150525      150526      150527  \n0   21.181818  33.409091   34.000000   21.151515   33.636364   33.969697  \n1  102.883333  91.600000  105.733333  114.583333  103.983333  118.033333  \n2   91.655172  94.327586  105.862069   91.655172   94.293103  105.827586  \n3    3.000000   5.200000    6.800000    3.000000    5.200000    6.800000  \n4    6.395833   0.229167    2.958333    6.479167    0.208333    2.958333  \n\n[5 rows x 151039 columns]\n","output_type":"stream"}],"execution_count":80},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\n\n# Combine the text-based features and video-based features for early fusion\ntext_features_combined = np.hstack((train_text_features, train_video_features))\nsentiment_labels = train_df['Sentiment']\n\n# Split the dataset into training and validation sets (80% train, 20% validation)\nX_train_set, X_validation_set, y_train_set, y_validation_set = train_test_split(text_features_combined, sentiment_labels, test_size=0.2, random_state=42)\n\n# Initialize a RandomForestClassifier\nclassifier_model = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Fit the model to the training data\nclassifier_model.fit(X_train_set, y_train_set)\n\n# Make predictions on the validation set\npredicted_labels = classifier_model.predict(X_validation_set)\n\n# Display classification metrics for the model\nprint(classification_report(y_validation_set, predicted_labels))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T18:49:36.514160Z","iopub.execute_input":"2024-11-11T18:49:36.514722Z","iopub.status.idle":"2024-11-11T18:49:57.528528Z","shell.execute_reply.started":"2024-11-11T18:49:36.514669Z","shell.execute_reply":"2024-11-11T18:49:57.527302Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n    negative       0.50      0.15      0.23        61\n     neutral       0.50      0.90      0.64        97\n    positive       0.25      0.05      0.08        42\n\n    accuracy                           0.49       200\n   macro avg       0.42      0.36      0.32       200\nweighted avg       0.45      0.49      0.40       200\n\n","output_type":"stream"}],"execution_count":81},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report\n\n# Evaluate accuracy for the model\ny_pred = model.predict(X_val)\naccuracy = accuracy_score(y_val, y_pred)\nprint(\"Model_Accuracy:\", accuracy*100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T18:49:57.529797Z","iopub.execute_input":"2024-11-11T18:49:57.530128Z","iopub.status.idle":"2024-11-11T18:49:57.610397Z","shell.execute_reply.started":"2024-11-11T18:49:57.530094Z","shell.execute_reply":"2024-11-11T18:49:57.609323Z"}},"outputs":[{"name":"stdout","text":"Model_Accuracy: 47.0\n","output_type":"stream"}],"execution_count":82},{"cell_type":"code","source":"# Generate features for the test data (video features)\ntest_video_features = np.array([extract_video_features(path) for path in test_df['video_clip_path']])\n\n# Combine the test data's text and video features for prediction\nX_test = np.hstack((test_friends_text_features, test_video_features))\n\n# Predict on test data\nTests_Predictions = model.predict(X_test)\n\n# Create submission DataFrame with \"Sr No.\" from 1 to 100\nsubmission_df = pd.DataFrame({\n    'Sr No.': test_df['Sr No.'],\n    'Sentiment': Tests_Predictions\n})\n\n# Save predictions to CSV for submission\nsubmission_df.to_csv(\"submission.csv\", index=False)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T18:51:05.688575Z","iopub.execute_input":"2024-11-11T18:51:05.689312Z","iopub.status.idle":"2024-11-11T18:51:29.230195Z","shell.execute_reply.started":"2024-11-11T18:51:05.689254Z","shell.execute_reply":"2024-11-11T18:51:29.229309Z"}},"outputs":[],"execution_count":84}]}